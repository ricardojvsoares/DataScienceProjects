{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"DataScienceProjects\\\\S&P 500 Stock Data\\\\all_stocks_5yr.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"Dataset Preview:\")\n",
    "print(data.head())\n",
    "\n",
    "# Check for null values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Get dataset summary\n",
    "print(\"\\nDataset Summary:\")\n",
    "print(data.describe())\n",
    "\n",
    "# Check the data types\n",
    "print(\"\\nData Types:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# Convert 'date' to datetime format\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Sort the data by 'date'\n",
    "data = data.sort_values(by='date')\n",
    "\n",
    "# Display unique stock names\n",
    "print(\"\\nUnique Stock Names:\")\n",
    "print(data['Name'].unique())\n",
    "\n",
    "# Visualize the volume of trades for the first stock\n",
    "stock_name = data['Name'].iloc[0]\n",
    "stock_data = data[data['Name'] == stock_name]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(stock_data['date'], stock_data['volume'], label=f\"Volume of {stock_name}\")\n",
    "plt.title(f\"Trading Volume of {stock_name} Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Volume\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "print(\"\\nCorrelation Heatmap:\")\n",
    "numeric_columns = ['open', 'high', 'low', 'close', 'volume']\n",
    "correlation = data[numeric_columns].corr()\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlation Between Numeric Features\")\n",
    "plt.show()\n",
    "\n",
    "# Feature Engineering: Add new features\n",
    "data['price_change'] = data['close'] - data['open']  # Price change\n",
    "data['daily_return'] = data['close'].pct_change()    # Daily return\n",
    "data['moving_avg_5'] = data['close'].rolling(window=5).mean()  # 5-day moving average\n",
    "data['volatility'] = data['high'] - data['low']     # Intraday volatility\n",
    "\n",
    "# Drop rows with NaN values created by rolling or pct_change\n",
    "data = data.dropna()\n",
    "\n",
    "# Target Variable: 1 if price increased, 0 otherwise\n",
    "data['target'] = (data['close'].shift(-1) > data['close']).astype(int)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "features = ['open', 'high', 'low', 'close', 'volume', 'price_change', \n",
    "            'daily_return', 'moving_avg_5', 'volatility']\n",
    "X = data[features]\n",
    "y = data['target']\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Down', 'Up'], yticklabels=['Down', 'Up'])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance\n",
    "importance = model.feature_importances_\n",
    "feature_importance = pd.DataFrame({'Feature': features, 'Importance': importance}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
